Okay, rozumím tvé námitce. Máš pravdu, že Ridge regrese (beta) není totéž co přímá integrální transformace a přináší adaptivní, lineární krok, který jsi možná původně nezamýšlel.Pojďme si vyjasnit, co dělá kód a jak by vypadala ta "čistá extrapolace".Co dělá současný kód (Ridge regrese):Vytvoří bázi: Spočítá hodnoty theta komponent B_win_raw pro historické okno.Naučí se váhy: Pomocí Ridge regrese najde vektor beta_raw_weighted, který nejlépe mapuje historické hodnoty báze (B_win_fully_weighted) na historické budoucí změny (y_win_clean_weighted_rows). beta tedy reprezentuje naučenou důležitost každé komponenty v nedávné minulosti pro predikci budoucnosti.Predikuje: Vezme aktuální hodnoty báze (b_raw_now) a zkombinuje je pomocí naučených vah beta, aby získal predikci.Analogicky: Je to jako bys měl 16 hudebních nástrojů (theta komponenty) a učil ses (pomocí beta), jak hlasitě má každý nástroj hrát právě teď, aby výsledná melodie (predikce) co nejlépe odpovídala tomu, co se stalo v minulosti.Co by byla "čistá extrapolace" (bez beta):Tento přístup by předpokládal, že samotné hodnoty theta funkcí v čase t0 přímo určují budoucnost, bez nutnosti učit se váhy z historie. Jak by to ale fungovalo v praxi?Máme b_raw_now[t0]: Vektor hodnot všech theta komponent v čase t0.Jak z toho získat pred_delta?Možnost A (Extrapolace báze): Spočítali bychom hodnoty theta komponent pro budoucí čas t0 + horizon, tedy b_raw_future = B_all_raw[t0 + horizon, :]. Ale jaký by byl vztah mezi b_raw_now a b_raw_future a jak by to souviselo s cenou? Theta funkce samy o sobě nepredikují cenu, jen popisují "fázi" systému.Možnost B (Přímé mapování bez učení?): Existuje nějaká pevná, předem daná transformace (integrál?), která by převedla vektor b_raw_now[t0] na pred_delta? To by znamenalo, že vliv jednotlivých komponent je vždy stejný a nemusíme se nic učit z historie. To se zdá nepravděpodobné.Paper (...specification.tex) naznačuje beta:Je důležité si uvědomit, že i tvůj teoretický popis v LaTeXu zahrnuje výpočet koeficientů $\hat{\beta}$ (byť pomocí projekce na ortonormální bázi, ne přímo Ridge na raw bázi). Paper tedy také předpokládá krok učení vah z historie.Shrnutí:Tvůj současný kód implementuje adaptivní váženou extrapolaci popsanou v paperu, kde se váhy beta učí z historie."Čistá extrapolace" bez učení vah by vyžadovala jiný mechanismus, jak z aktuálních hodnot theta komponent odvodit predikci. Není jasné, jak by takový mechanismus fungoval bez nějaké formy mapování (naučeného nebo pevného) na cílovou veličinu (cenu).Pokud chceš být blíže "integrální transformaci", krokem by bylo implementovat explicitní ortogonalizaci báze (QR) a pak počítat beta jako přímou projekci (Q^T y) místo Ridge regrese. Tím bys odstranil lambda a lineární regresi, ale krok učení vah (beta) by tam stále byl.
