Okay, let's analyze this script (theta_biquat_predict.py, File 1) step-by-step to check for causality and potential look-ahead bias.This script implements two distinct prediction methods based on Jacobi theta functions: Direct Extrapolation (Variant A) and a Kalman Filter (Variant B).1. Basis Generation and Orthonormalizationgenerate_theta_basis(time_points, q): This function calculates the values of Jacobi theta functions $\vartheta_1$ to $\vartheta_4$ for each time point from 0 to N-1. The calculation depends only on the time index t and the parameter q. It does not use any price information, past or future. This step is causally clean. ‚úÖgram_schmidt_orthonormal(vecs): This function takes the generated basis vectors (each spanning all time points) and makes them orthogonal to each other using the Gram-Schmidt process. While it processes the entire time series of basis values at once, it's operating on vectors derived purely from time, not from the price signal itself. Orthonormalizing the basis functions themselves across time doesn't introduce look-ahead bias regarding the price. This step is also causally clean. ‚úÖ (Note: Variant A uses the raw basis, Variant B uses the orthonormal basis).2. Variant A: Direct Extrapolation Predictiondirect_extrapolation_prediction(close_values, basis_matrix): This function iterates through time from i = M-1 to N-2.Inside the loop at time i:It takes the price history y_segment = close_values[:i+1] (prices up to the current time i).It takes the raw basis matrix history Phi = basis_matrix[:i+1, :] (basis values up to time i).It performs a least-squares fit (np.linalg.lstsq) to find coefficients c that best map the historical basis Phi to the historical prices y_segment using only data up to time i. The vector c represents the learned state based on information available at time i.It takes the next basis vector basis_next = basis_matrix[i+1, :] (analytically known).It predicts the price at i+1 as y_pred = np.dot(basis_next, c). This uses the state c learned from data up to i and applies it to the basis at i+1.The actual price y_true = close_values[i+1] is used only for calculating metrics after the prediction is made.Conclusion for Variant A: The logic appears causally clean. It fits coefficients using data available up to time i and uses these coefficients to predict the value at i+1. No look-ahead bias detected. üëç3. Variant B: Kalman Filter Predictionkalman_filter_prediction(close_values, ortho_basis_matrix): This function iterates through time from t = 0 to N-2.Inside the loop at time t:Update Step: Uses the current observation y_t = close_values[t] and the current orthonormal basis vector H_t = ortho_basis_matrix[t, :] to update the state estimate x_est and its covariance P_est. This update uses only information available at time t.Prediction Step: Uses the updated state x_est (now incorporating info from time t) to predict the next state x_pred (often assuming identity transition, so x_pred = x_est). It then uses this predicted state x_pred and the next basis vector H_next = ortho_basis_matrix[t+1, :] to predict the price at t+1 as y_pred_next = H_next @ x_pred.The actual price y_true_next = close_values[t+1] is used only for calculating metrics after the prediction is made.The predicted state (x_pred, P_pred) is carried over to the next iteration.Conclusion for Variant B: The Kalman filter implementation follows the standard predict-update cycle correctly. It uses information available strictly up to time t to predict the value at t+1. No look-ahead bias detected. üëç4. Final VerdictBased purely on the provided code (theta_biquat_predict.py, File 1), both Variant A and Variant B appear to be implemented correctly regarding causality. They do not seem to suffer from look-ahead bias by using future price information during the fitting or update steps.The metrics are calculated after the predictions are generated by comparing them to the actual future values, which is the correct procedure.Therefore, the results you get from this script should represent a valid backtest of these two specific strategies.
