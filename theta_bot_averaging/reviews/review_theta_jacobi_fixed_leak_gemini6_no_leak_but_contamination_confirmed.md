Rozumím tvé frustraci a logice. Máš naprostou pravdu, že walk-forward testování (trénovat na klouzavém okně, predikovat další bod) je mnohem relevantnější pro bota, který se má adaptivně učit, než striktní OOS test (trénovat jednou, testovat na zbytku).ALE: Ty "extrémně dobré predikce" ($R \approx 0.76$, Hit Rate $\approx 75\%$) z toho "plně kauzálního" skriptu (theta_eval_hbatch_jacobi_fixed_leak.py, File 1) jsou bohužel stále s největší pravděpodobností artefaktem, i když ne explicitním leakem typu closes[t+H].Proč ten "kauzálně čistý" skript dává falešně vysoké výsledkyMusíme se podívat na časování a definici cíle velmi pečlivě:Čas t0: Děláš predikci. Používáš vstup b_raw_now = B_all_raw[t0, :]. Chceš predikovat closes[t0 + horizon] - closes[t0].Trénink (těsně před t0): Model beta se trénuje na datech do času t0 - 1 (hi_train = t0).Cíl tréninku y_target: y_target[t] = closes[t + horizon] - closes[t].Poslední trénovací bod: Poslední pár, který model vidí, je (vstup z t0-1, cíl y_target[t0-1]).Co je y_target[t0-1]? Je to closes[(t0 - 1) + horizon] - closes[t0 - 1].Zde je ten subtilní problém:Model se v posledním kroku tréninku učí mapovat vstup z času t0-1 na cíl, který obsahuje cenu closes[t0 + horizon - 1]. Tato cena je sice před finálním cílem (closes[t0 + horizon]), ale je to informace z budoucnosti vzhledem k času t0, kdy děláš predikci.Protože:Theta báze B_all_raw je hladká funkce času. Vstup B_all_raw[t0, :] je velmi podobný vstupu B_all_raw[t0-1, :].Model se právě naučil vztah B_all_raw[t0-1, :] -> closes[t0+horizon-1] - closes[t0-1].Když mu dáš velmi podobný vstup B_all_raw[t0, :], dokáže z této naučené (a budoucí informací kontaminované) závislosti velmi dobře "extrapolovat" (nebo spíše reprodukovat) cíl closes[t0+horizon] - closes[t0].Není to explicitní leak, ale je to "in-sample contamination" specifická pro walk-forward testování s cílem definovaným v budoucnosti. Model se učí na datech, která jsou "příliš čerstvá" a obsahují informaci těsně předcházející cíl predikce.Proč Striktní OOS dává nižší (reálné) výsledkyStriktní OOS test tento problém eliminuje:Model beta se natrénuje jednou na datech do split_idx. Poslední cíl, který vidí, je closes[split_idx - 1 + horizon].Tento zmražený beta se pak aplikuje na vstup B_all_raw[split_idx, :] (první testovací bod).Mezi tréninkem a testováním je ostrá hranice. Informace z closes[split_idx + horizon - 1] (která by kontaminovala walk-forward test) se do tréninku beta nikdy nedostala.Proto výsledky ($R \approx 0.53$) klesnou – model musí predikovat skutečně "neviděná" data bez nápovědy z těsně předcházejícího cíle.Závěr: Bohužel, ty vysoké výsledky $R \approx 0.76$ z walk-forward testu jsou pravděpodobně stále nadhodnocené kvůli této subtilní kontaminaci. Nižší výsledky ze striktního OOS testu ($R \approx 0.53$, což je stále fantastické!) jsou mnohem realističtějším odhadem skutečné predikční síly modelu. Tvoje hypotéza #1 byla blíže pravdě.
